
$Id$

1/20/2007 karl
    * Added "-array" and "-array_with_nulls" search options.  Both take an
      array name, -array will set the fields all nonnull fields into the
      array and unset any fields that are null.  -array_with_nulls will
      set all the fields from the row into the named array, substituting
      the null value (by default, an empty string, but can be set in the
      creator table) for any fields that are null.

1/21/2007 karl
    * Added tests for -array and -array_with_nulls.

    * Updated docs, including stuff on how to make remote speed tables go fast.

1/20/2007 karl
    * Added "-array" and "-array_with_nulls" search options.  Both take an
      array name, -array will set all non-null fields into the
      array *and* unset any fields that are null.  -array_with_nulls will
      set all the fields from the row into the named array, substituting
      the null value (by default, an empty string, but can be set in the
      creator table) for any fields that are null.

1/16/2007 karl
    * Added new method, "batch", which takes a list of ctable commands,
      minus the table name (as that's implicit) and invokes each element
      as a method invocation on the current ctable, without invoking the
      tcl interpreter, accumulating results for elements that return 
      results or generate error returns, returning those as a list at
      the end.  
      
      This is pretty amazing.  
      
      This isn't so important for local ctables but will be a big win for 
      remote ctables, saving many network round-trips when there are many
      commands in the batch.

      search is not supported in a batch and the results are undefined.

    * Added "command" to the ctable creator table as a pointer to the
      ${table}ObjCmd, allowing direct calls from C to all Tcl-callable
      speed table functions without requiring the use of the Tcl interpreter!

    * Change -include_field_names in search to -with_field_names in 
      preparation for adding the same to read_tabsep.

    * Fix bug in -with_field_names where it just emitted the fields left
      to right instead of actually looking them up in the field list.

      Worked fine for all fields, not so good with a subset.

    * Updated speed table pages file (and export new PDF) to include docs on
      the "in" search term.

    * Hashtable key was getting deleted twice when a row was deleted.
      Fixed this and added tests.

    * Change all the ctable->creatorTable->stuff to ctable->creator->stuff.

1/15/2007 karl
    * Complete work on search+ where the first compare term is "in" and
      the field being compared is indexed.  Tests updated, although
      more comprehensive tests need to be written.

      Still not done, "in" when not the first term or the field isn't
      indexed, etc.

      Make "in" take a list of match values as the third argument.
      We originally did not have a sublist, it was "in field val val..."

    * Mapped the following structs to typedefs and made it use the typedefs:

        struct ctableTable -> CTable

	struct ctableSearchStruct -> CTableSearch

	struct ctableSearchComponentStruct -> CTableSearchComponent

	struct ctable_linkedListNodeStruct -> ctable_LinkedListNode

	struct ctable_baseRow -> ctable_BaseRows

	struct ctableCreatorTable -> ctable_CreatorTable

	struct ctableFieldInfo -> ctable_FieldInfo

    * Add testing the "in" search compare function to the big tests.

    * Generate a second million row test file containing some IP
      addresses and MAC addresses for testing that stuff.

1/14/2007 karl
    * Begin laying in the infrastructure for the new "in" search term.

1/12/2007 karl
    * To the command that's created corresponding to a C
      extension, add a new option, builder_version, which
      will return the package version of the ctable
      compiler that built it.

    * Include the modification time of the ctable library directory
      ($srcDir) in what we compare to see if we need to rebuild, 
      so if the mtime has changed, we'll regenerate and recompile 
      the extension.  This is at least helpful for the ctables 
      developers.

    * Fixed bug in search using -array_get with a specified set of fields
      (instead of all fields by default).  It used to not include the
      field names in the key-value pairs under those circumstances.

    * Removed superfluous argument to ctable_SetupSearch -- routines
      that have access to the ctable structure can find their own
      list of field names.

    * Inhibited generating index checking code in additional places
      when an index isn't defined for a field and reworked setting
      values around allowing and not allowing null values and having
      and not having indexes.

    * Added test for search's array_get and limited-field array_get.

    * Added test for search's "false" compare function and more tests
      for the "fields" method.

1/10/2007 karl
    * Allow optional -nokeys argument to import_postgres_result.

    * Make the *_delete routine take the ctable and a flag that says
      CTABLE_INDEX_NORMAL if the row is in its indexes, etc, or
      CTABLE_INDEX_PRIVATE if it isn't.  (For instance, rows generated
      as part of search components are never inserted into a table).

      If the delete type is "normal", the *_delete routine will remove
      the row from all of the indexes that are in existence for that
      table and it will remove the row from the table's hash table.

      In either case, the delete routine will delete any varstrings that
      are part of the row and then delete the row itself.

      This means that code doesn't have to know how and when to remove the
      row from any indexes.

    * By the above changes and a bit more, fixed a memory leak when
      completing searches.

    * Altered ctable_RemoveFromIndex and ctable_RemoveFromAllIndexes to
      not take an interpreter and have a void return as they cannot fail.

    * Now that performance has gotten a lot of attention we are turning
      our attention, at least temporarily, to memory utilization.

      Bring the hash table entry inline into the row being generated.
      Get rid of code for different hash key types.
      This saves two pointers, 8 bytes per row on a 32-bit machine,
      16 bytes per row if you have 64-bit pointers.

      This reduced the program size after loading the million-row test
      data set in "bigtests", with no indexes defined, on a Pentium 4 from
      123 MB to 105 MB, a 17% reduction in memory usage, with the loaded
      data now using about 2.5 times the amount of space used by the
      corresponding text file.  It grows to 190 MB with two indexes defined 
      and fully populated.

    * Include the build-with-compiler-debugging flag in what we compare
      to see if we need to rebuild, so if that flag is changed, we'll
      regenerate and recompile the extension.

1/8/2007 karl
    * Fix critical memory leak in *_set_from_tabsep, used by read_tabsep.

    * Fix minor memory leak in ctable_SearchAction that could occur
      for matching rows under certain circumstances based on what form 
      the results were requested in.

1/7/2007 karl
    * Update "reset" and "destroy" methods to walk the table using
      the all-rows linked list instead of walking the hash table,
      resulting in a 33% performance improvement deleteing a
      million-row four-element table on a G4.

    * Revert handling of the registered proc hashtables to using the
      Tcl hashtable routines rather than our custom version as the
      custom version is about to evolve specifically to go into rows
      of ctables.

    * Copy Hash.3 that documents hashtable routines in Tcl and update it
      for changes made for our private version.  More to come.

    * Change speedtables hash routines to have compare routines return
      0 for a match, -1 for less than and 1 for greater than rather than
      1 for a match and 0 for "not equal" in preparation of using the
      actual field in the row as the hash key and bootstrapping our
      existing per-field compare routines to do the comparing.

    * When generating the field compare routine for strings, check the
      first characters for nonequality and handle explicitly, only
      calling strcmp if the first characters are identical.

1/6/2007 karl
    * Make write_tabsep walk the all-rows linked list instead of the
      hashtable, for no good reason as it's deprecated anyway but
      I guess it's good practice.

1/4/2007 karl
    * Adapt the Tcl hashtable routines for speedtables's own use.

    * Modify the hashtable routines to allocate 16 buckets initially,
      instead of 4, and to grow the tables 16X at a time instead of
      4X at a time, resulting in far fewer hashtable rebuilds when
      inserting into a large table, providing about a 7% increase
      in overall speed table insertion performance.

1/4/2007 karl
    * Simplify init-exten.c-subst by exploiting the not per-definition
      customized "struct ctableCreatorTable", removing a substitution,
      and making speed tables compile properly again when defining
      multiple tables.

1/3/2007 karl
    * Support unique indexes using "unique 1" in field definition.

      Warning - as yet unresolved bug can result in coredumps when
      a field defined as unique has a row's value changed to something
      that's a duplicate.

    * Support "=" as a "magic" search+ first search term (in addition to
      "range", which is already support) to use the field's skip list index,
      if it exists, and super accelerate the search.

    * Even if they're searching with -count 0, if they've specified that
      they want field names emitted, emit them.

    * In search code, pull out common code between search and search+
      in preparation for unifying search and search+ and even adding
      additional ways to walk such as safe walking to allow deletion
      of matches, etc.

    * In search code, pull matchCount, tailoredWalk and sortTable into
      the ctable search structure rather than passing them around
      discretely.

    * Extract about 100 lines of common code between search and search+
      and turn it into a function called by both.  It's a start.

1/2/2007 karl
    * Make skip list insert routine "jsw_sinsert_linked" support a "unique" 
      flag that, if set, has the routine return 0 when an insert would result
      in a row with a duplicate key for that indexed field.  If unique is
      0, duplicates are allowed.

    * Use embedded array of pointers to nodes inside a skip list node so
      that skip list node generation requires only one memory allocation
      instead of two and a requiring only a corresponding single free
      when they're deleted.

      This change resulted in a 14.6% increase in index creation performance
      on a PowerPC G4 running the match-test-index2.tcl test and search+
      query performance improvements of between 9% and 16%.

      Running match-test-index3.tcl, which generates the million-row index
      on the fly, there is no performance increase in indexing but queries
      again run 12% to 16% faster.

      A caution with regard to these kinds of measurements, speed tables
      performance is greatly affected by the size of your processor's L1
      cache.

1/1/2007 karl
    * Update speed table pages file (and export new PDF) to include docs on
      the key-value pairs that can follow a field definition, including
      "indexed", "notnull", "default", "length", and "unique".

12/30/2006 karl
    * Add introspection.txt doc that had been sitting around that has the
      rationale and design for adding introspection as committed on 12/28.

12/28/2006 karl
    * Maintain all the key-value pairs for each defined field and make them
      accessible in ctable creator table structures via the per-field
      ctableFieldInfo struct, one for property keys  and one for property 
      values.  Also add "field" method to get properties, a key-value
      property list, or the value of any field's property via stuff like
      $ctable field $fieldName property $propName, etc.

12/25/2006 karl
    * When generating the search compare routine for a given table, use
      the field compare routines without distinguishing the field type
      if the comparison type is <, <=, =, !=, >, >= or "range".  This is
      faster and makes range work when it isn't the first comparison routine 
      with "search+" and under any circumstances with "search".

    * Detect attempts to invoke comparison types that aren't implemented
      for a given data type and panic rather than just make it do nothing.
      Catches "range" compares that aren't the first element of a search+
      as we have to rethink searching to implement "range".

      Probably should be either made to work or detected and errored upon at 
      search creation time -- we can't error out from a compare routine 
      because there's no error return path -- they return -1, 0 or 1.

    * Update docs.  Add the PDF files to CVS. A problem with how Pages 
      works makes putting the Pages doc in CVS painful related to it
      blowing away the CVS directories within itself.

12/24/2006 karl
    * When defining fields "notnull 1", avoid generating null checking
      and comparing code, hardwire null search results, etc.
      Major performance boost when fields are defined notnull, 5% - 50%
      when searching, for instance.

    * During generation, set field definition key-value pairs into arrays 
      named after the fields inside the ::ctable::fields namespace and access 
      those via upvar rather than constantly array setting a local array
      from the field definition key-value pairs.  It's cleaner and makes
      generation faster.

    * Make "fields" generate the field list using Tcl objects of the field
      names that we already had laying around, rather than generating new
      ones from the field name strings.  Small optimization but there it was.

12/23/2006 karl
    * Made automatic row IDs (created when reading tabsep-data) not reset
      upon subsequent read_tabsep, but do reset after "reset" method is
      invoked.

12/20/2006 karl
    * Added new "index" method suboption, $ctable index span $fieldName,
      which will return a list containing the lexically lowest index value
      and lexically highest index value for the indexed field specified.

    * Added search comparisons "notmatch" and "notmatch_case", which are the 
      inverse of "match" and "match_case".  This will allow ctables to be a
      drop-in replacement for using the DIOdisplay package to create web stuff,
      and will have to do until we bite the bullet and write more general
      purpose comparison routines, i.e. with expression booleans other than 
      the implicit "and".

    * Make the search routine construct a row and store the field it wants
      to compare against into the row with the standard functions, then
      pass that special row to the comparison routine and clean up aftewards.
      It's faster and it makes mac and inet types be searchable, rangeable,
      etc.

    * Factor common code for writing tab-separated field names into a
      new function, ctable_WriteFieldNames.

    * Remove conditional compliation of new-style linked list traversal
      in search versus old-style hashtable traversal -- we're fully
      committed to the higher-performing linked list traversal now.

    * Fix bug with -key in search+ where, when emitting a list of
      field names, we don't include the "_key" pseudofield.

    * Make bigtests use the BSD extension to calculate actual elapsed
      system and user time, if available, and fall back to using
      Tcl's "time" command if that extension is unavailable.

    * Improve search performance by doing less pointer dereferencing
      and inlining some more stuff.

    * Reordering structs to have pointers first produces a minor
      speed improvement and less padding of C structures.

12/19/2006 karl
    * Proceduralize generating index inserting and deleting code and
      don't generate it for a field when an index isn't defined on that
      field.

12/18/2006 karl
    * Fix bug where skip list code assumed it would get 64 bits of random
      number instead of the 32 it got, making skip lists really slow
      on 64-bit machines like AMD64 (where sizeof(size_t) == 8)

    * Moved where the *_setup routine got called when initializing a
      creator table so the per-field field name object pointers got
      set properly.  This fixes "indexed" and "indexable" options to
      "index" method.

12/16/2006 karl
    * Added "indexable" and "indexed" suboptions to the ctable "index"
      method to list the names of the fields that can be indexed
      (indexes were defined on the fields when the table was created)
      and to list the names of the fields that have indexes currently
      defined against them.

12/15/2006 karl
    * Fixed sort to work in both search and search+.  (It previously did not
      work with search+.)  Fold ctable_SearchAction and ctable_SkipSearchAction
      into one, also gaining the ability to specify -key in search+.

    * Fixed bug in "reset" method, introduced with indexes, where indexes
      weren't getting deleted and the doubly linked list of all rows was
      not getting reset.

    * Created 25 pages of ctables documentation in Pages, starting with
      doc.txt.

12/14/2006 karl
    * Indexes now support duplicate entries.

12/7/2006 karl
    * Major performance boost by maintaining a linked list among all of
      the rows of a table and walking that while searching rather than
      enumerating the hash table.  Increased search performance from
      for a brute-force unanchored text search of 1,000,000 rows by
      more than threefold.

    * Implement an array of linked list nodes defined in the row
      structure definition, one for all rows (index 0) and the rest
      for fields declared as indexable, in preparation for supporting
      indexes that can contain duplicate entries.  Also they're defined
      in such a way that they are guaranteed to be in the same place in
      all rows so different code can use a "base row" definition and
      access the linked list nodes without having been generated to
      understand the data that follows it.

12/6/2006 karl
    * Added code to repeatably generate the test data in bigtests and got 
      rid of the 24 meg file of test data that was previously there.

12/5/2006 karl
    * Version 3.0 tagged for release.

    * Resolve the bugs in search with offset and limit specified and
      the different results whether it was sorted or unsorted.

    * Merge the skiplist development branch back into the mainline ctables
      CVS branch.

    * Bring search limit with and without sort into compliance that limit is 
      the limit on the number of rows returned.

    * Revived "write_tabsep" and "foreach" at the request of the userbase,
      although they are still to be considered deprecated.

    * Make $table index create $field take an optional argument which is
      the depth of the skip list, like 24 would be good if you had 4M
      rows.  (This should be more hidden but it's still in dev.)

    * When building for source-level debugging, still use some level
      of optimization.

    * Updated docs to reflect usage of "index" method and fully document
      "search" method.

    * Fix up argument error message for search to include all the options.

12/4/2006 karl
    * Skip list indexes are working for creation, dropping, inserting,
      updating, and searching.

    * Added "search+" that works like search but on skip lists instead
      of the hash table.  This isn't the permanent solution.

    * Added pointers to functions to make empty rows, set elements
      of rows, set elements of rows to null, get values from rows
      to the ctable table structure.  It's getting to where
      you can write all sorts of high speed C ctable access stuff
      that isn't tailored to a specific data structure.

      Internally you see this in how much code is in ctable_search.c
      and how that code makes use of these pointers to access fields
      in tables without knowing how those tables are structured.

    * Got rid of generating custom pointer names in tons of places,
      substituting "row" instead, significantly simplifying the
      code.

    * "...index count $field" is now working. 

    * Attempts to insert duplicate entries in skip lists is now an error.
      We'll eventually support having duplicate keys but not currently.

    * Propagate the Tcl interpreter pointer, ctable pointer, and whether 
      a row is new or not into *_set, *_set_fieldobj, *_incr, 
      *_incr_fieldobj and *_set_null routines.  It's a lot of overhead
      to allow fields in a table to be indexed on demand, but since
      we're generating the code, we can also not generate if we're
      somehow told there won't be indexes or on what fields there
      won't be indexes.

12/3/2006 karl
    * Add "list" option to "... index" to get a list of indices for
      the given field's index.  While this will be wildly inefficient
      with hundreds of thousands of records, it's handy to facilitate
      testing and verification that the indexes are in sync.

    * Add "count" option to "... index" method to get the count.
      Currently inoperative as the skip list library defined the
      count but doesn't manage it.  We'll fix that shortly.

    * Add "notnull 1" options to inhibit generation of null check code
      for a field.  **Incomplete**  be addressed in numerous places
      and may not even be worth it(?)

    * Tighten up generated code by stripping leading and trailing newline
      from substituted multi-line elements.

12/2/2006 karl
    * Propagate the ctableTable pointer down into the ${table}_set
      routine in preparation of handling triggers/indexes.

    * Create a "dump" suboption for indexes.

    * Propagate a pointer to the table-specific ${table}_get_string function
      into the creatorTable struct for the corresponding table to that
      routines with no specific awareness of how a table has been
      generated can still get the contents of fields and stuff.


12/1/2006 karl
    * Generate new per-field row-to-row comparison routines for use with
      skip lists and, eventually, sort comparisons and search comparisons.

    * For each table create an array of pointers to field compare functions 
      indexed by field number.

    * When creating a skip list, store the compare function by getting it
      from the creator table structure.

    * Add new ctable method, "index", with subcommands "create" and "drop"

    * Remove deprecated "foreach", "sort", "write_tabsep", "import"
      and "export" methods.

    * Migrate another hundred lines out of gentable.tcl and into
      command-body.c-subst, reducing complexity in gentable.tcl.

11/30/2006 karl
    * Standardize field creation to always be key-value pairs, so you
      now might say "varchar foo default bar" instead of
      "varchar foo bar" so that you can do other stuff like
      "index 1 unique 1"

    * Make new command the same name as the extension name, except the first
      char is uppercase (strangely, something to do with TEA), that will
      give you back the definition that made the C extension in the first
      place.

    * Add new method to tables, cextension, that returns the C extension
      that defined them.

    * Created skiplist development branch.  Got skiplist code to
      install in the ctable package and compile cleanly within 
      ctables.  Merged development branch back into mainline.

11/29/2006 karl
    * Tagged 2_0 for release.

    * Doubled performance for searches with "match" components
      where we use ultra-fast Boyer-Moore when the search is unanchored
      (*pattern*) and not too fancy (no embedded []?*\ characters).

    * Add a switch to gentable.tcl to show compiler command lines.

11/28/2006 karl
    * Fix bug where, when searching with no sorting and a limit, you'd get
      one less record than you'd asked for even if one more was available.

11/26/2006 karl
    * Add -include_field_names to search.  If set to true and using
      -write_tabsep, will make the first line be the field names
      that matching.

    * Manage varstring space a little more efficiently by not freeing
      the string whenever it gets set if it's already set.  By looking
      to see what was allocated, we reuse what's there if it's big enough.

    * Add "incr" method.  It takes take key-value pairs or a list of
      key-value pairs.  It will increment each numeric field by
      the corresponding amount and return a list of the new values
      of all incremented fields.

    * Add new compare methods "match" and "match_case" that perform
      a Tcl_StringMatch on the field (currently varchar-only) and
      select it if it matches else skips it.  match is case-insensitive
      and match_case is case-sensitive.

11/25/2006 karl
    * In search's -sort option, fields in the field list that begin with
      a dash are sorted in descending order rather than ascending order.

    * Make "null" and "notnull" comparisons work.

11/24/2006 karl
    * Rename search's -list option to -get.  Rename its -array to -array_get
      and add -array-get_with_nulls.

    * Pull the number of fields, array of field types and array of elements
      needing quoting into the table creator structure.

    * Bring pointers to functions lappend_field_and_nameobj and
      lappend_nonnull_field_and_nameobj into the table creator structure.

    * If no reference fields are specified with a search (-fields list),
      you get all fields by default.

    * Convert ${table}_gen_nonnull_keyvalue_list and 
      ${table}_gen_keyvalue_list to return a Tcl_Obj rather than
      setting the interpreter result object and return TCL_OK
      so that they're more general purpose.  Modify code that
      previously called this to set the interpreter obj result
      with the result.

11/23/2006 karl
    * The "foreach" and "sort" methods are deprecated in favor of
      "search" but will be left in until legacy code can be updated.

    * Simplify things by using standardized table creator and table
      structures rather than generating custom ones for each 
      ctable -- we hide the differences behind the value of the
      hashtable and cast in our custom-generated code.

    * Get rid of the TAILQ stuff -- it wasn't fully implemeneted and
      was a good idea but it's also hackish in terms of it's cpp
      macros that create all the forward and backward casts -- needs
      thought.

    * Migrate standardized structures that are not custom-generated
      into a new include file, ctable.h

    * Reference the registered proc table pointer from the master
      structure for the ctable type.

11/22/2006 karl
    * Factored out a 702-line piece of code for the main body of
      generated ctable code into its own file to make things
      more manageable.

11/21/2006 karl
    * write_tabsep now works (or again works) if no field names
      are specified.

11/15/2006 karl
    * Switch debugging off by default.

    * Add the -nokey switch to import_tabsep and export_tabsep.  If set,
      export_tabsep will not include the key in what it emits, and 
      import_tabsep will self-generate an ascending integer key when
      importing.

    * Make linking with debug libraries and generating with compiler
      debugging more parameterized.

    * Make sort comparison of MAC and IP addresses work better or,
      more to the point, work at all.

    * When a row fails input checks during read_tabsep, report the line
      number in the error message.

    * Update documentation.

11/1/2006 karl
    * Add a sort method that lets you sort on multiple fields and call
      through to a callback that processes them in order, like foreach.
      Can't currently do descending and arguments are positional --
      would like to have a "walk" method that can sort, etc.

9/14/2006 karl
    * Expand the set command to allow it to take a list of key-value
      pairs in addition to its existing functionality.  This allows
      replacing     eval foo set $key [array get dataArray]
      with          foo set $key [array get dataArray]

9/9/2006 karl
    * Add an ability to specify a pattern when reading and writing
      tab-separated data.  Currently supports "-glob pattern" in
      the read_tabsep and write_tabsep methods.  Pattern is compared
      to the key field.

8/15/2006 karl
    * Make the optional match pattern on "foreach" precede the code body
      rather than come after it.

7/19/2006 karl
    * Fairly decent job of documenting things as they are, although currently
      only in a "straight text" style.

7/10/2006 karl
    * Detect defining a table with no fields and report as an error rather
      than generating stuff the C compiler can't understand.

    * Catch errors defining ctables and save off the errorInfo traceback
      that's basically internal to ctable.  Made a new proc,
      ::ctable::get_error_info, that will return that info, and include
      a note in the error message to run that proc to see the internal
      errorInfo traceback.

    * Create new method, export, that's the analog of import.  It will
      export all fields or specified fields from each stored row by
      repeated calling the passed proc with an argument consisting of
      a list containing the key and all specified fields (or all fields,
      if no fields are specified.)

    * New C routines, *_dstring_append_get_tabsep that will generate
      tab-separated (and newline-terminated) fields from a row
      into a DString, and *_export_tabsep that will write all the
      rows in a table, tab-separated, to a channel.

    * Add of write_tabsep method that will write all of the fields, or
      the named fields, tab-separated, to the specified Tcl channel.
      Note that this currently does no quoting to make sure that
      tabs or newlines in strings don't screw things up.

    * New C routines, *_set_from_tabsep that will take a pointer to
      a row, a tab-separated import string, an array of field numbers
      and a number of fields and set the values into the row.  The
      first field is the key.
      *_import_tabsep reads lines from a channel and
      invokes *_set_from_tabsep on each line.

    * Add of read_tabsep method that, using the above routines,  will read 
      all of the fields, or the named fields, tab-separated, from the 
      specified Tcl channel.  Note that, like write_tabsep, this currently 
      does no quoting to make sure that tabs or newlines in strings don't 
      screw things up.

    * Make subobj datatype work again.

7/6/2006 karl
    * Fix the build on Darwin to not use the Postgres stuff.  Still haven't
      gotten the shared library on Darwin to work properly with the
      libpq and libpgtcl libraries.

7/5/2006 karl
    * Add a new method, array_get_nonnull, that will only return nonnull
      key-value pairs.

    * Make array_get work like array_get_nonnull, removing array_get_nonnull.
      Create array_get_with_nulls that replaces the prior behavior of
      array_get.

    * Added a new *_set_null function that, given a pointer to a row and
      a field number, will set the corresponding field's null value bit
      to true.  Note, there will be no reciprocal *_set_nonnull function
      because when the null bit is set, the corresponding value is
      undefined -- the only way to set a field nonnull is to set a value
      into it with the corresponding table's *_set routine.

    * New import_postgres_result can import a multirow PostgreSQL result
      directly into a ctable without any intervening per-row Tcl.  This
      is extremely fast.  Excluding the pg_exec overhead, on a 2.2 GHz
      AMD64 we can import 210,000 8-element rows per second.

7/4/2006 karl
    * Add a new method, null_value, to the meta table object that sets
      a null value that is returned by set and get when a field's value
      hasn't been set or has been set with the defined null_value.
      The default is an empty string.

    * Rework default stuff so that if a default value is defined, upon
      init of a new row, elements with default values will be set with
      the default values and the corresponding null value bits will be
      set to say that the elements are not null.  Anything without a
      default value predefined has its null bit set.

    * Change the syntax of the CExtension command to require a version
      number and take the code as the third argument.  This means the
      enter extension code body is specified on the CExtension command
      line via "{...}", which allowed EndExtension to move into the
      ctable namespace and be invoked automatically by CExtension at
      the end of code generation.  This will allow us to scarf off a
      complete copy of the code being fed to CExtension, which will
      let us see if it's the same as we got last time and keep us from
      doing a generate/compile/link phase if nothing's changed.

    * Create a CTableBuildPath command that sets where we will build.
      Include the version number in the filename of the generated C
      source and the object file that we compile to.

    * Scarf off the CExtension source code and compare it to what we're
      being asked to build now.  If they're the same, don't bother.

    * Record the CVS ID of the CTable generator in the scarfed off
      CExtension source code file (.ct file).  When checking to see
      if a build is necessary, also compare them.  If they don't match,
      do the build.  This way, if there's any change in the generator
      software, a build will occur even if the CExtension code hasn't
      changed.

    * Add the build path to the auto_path if it's not already there.
      Do a pkg_mkIndex on the build directory if we generated something.
      (This makes "package require" work for the extension we created.)

    * Add a Makefile.  It's currently lame.  Add automation to copy
      qhehe.h to the target directory if there isn't something there matching.


7/2/2006 karl
    * Keep track of string lengths for varstring fields to prevent lots
      of unnecessary counting and to lay the groundwork for character
      quoting that we'll be implementing soon, with a tradeoff off somewhat 
      larger row size as we're carrying string lengths along with pointers
      to strings in each rows.

    * For varstrings, create a Tcl_Obj containing the default value and
      increment its reference count at setup time, and when returning the 
      default value, simply return a pointer to that Tcl_Obj rather than
      creating a new string obj.

    * Optimization for varstring defaults.  If the default is an empty
      string, only generate one empty string obj default and use that
      as the default for each varstring with an empty string, rather than 
      creating an empty obj for each.

    * *_get C function now returns a (Tcl_Obj *) to an object representing
      the thing you asked for, rather than appending to a list on the
      Tcl result.  This makes it much more useful from C.

    * Now generating *_get_string function that takes a pointer to a row,
      a field in the row, a pointer to a length integer and a pointer to
      a Tcl_Obj that we use for utility purposes and it generates or
      otherwise finds the string and returns a pointer to the string,
      setting the length pointer to the length of the string if the length
      pointer isn't NULL.

    * Tagged Revision 1.1 (rev1_1)

    * When setting a string, compare that string to the default value and
      if it is the same as the default value, store a null pointer rather
      than allocating the string, copying it, and storing that pointer.
      When fetching a string, as before, provide the default value if the
      pointer within the row is null.

    * Enforce that field names must start with a letter and can contain
      only upper and lowercase letters, digits, and underscores.

    * Quote backslash sequences and control characters that are to
      appear in C strings using a cquote function generated by Peter
      at the next desk over at 6 pm on 7/3/2006.  Thank you, Peter.

    * Fix bug in array_get where no keys are specified.  It was
      returning exactly half as many fields as it should have. Oops.


7/1/2006 karl
    * Generate enum entries for fields using a proc.  That proc makes the
      field names unique, for example, FIELD_MAC now becomes for table
      "cable_device", FIELD_CABLE_DEVICE_MAC.

    * Add new "array_get" method that will let you one or more fields,
      or all fields, in "array get" format, i.e. key value [key value...]"

    * Make it work under FreeBSD as well as Darwin.  Eventually we will
      have to at least parse tclConfig.sh and possibly even have our
      own GNU autoconf thang.

    * Emit a enumerated typedef for the CTable types.  Also enumerate
      a corresponding array of char pointers containing the type names.

    * Emit an enum *_types for each defined table that has the enumerated
      ctable type for each field in the table.  This will allow us at
      runtime to easily and efficiently determine the type of any field from 
      C.  Soon, from Tcl as well.

    * Add of new method, fieldtype, which will return the CTable type of
      the passed-in field.

    * Add of new method, needs_quoting, which returns one if the passed-in
      field requires or may require quoting (i.e. could contain characters
      that could trip up a database insert, CSV export, or something like
      that.)

