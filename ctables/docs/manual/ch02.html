<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title>Speed Tables - Representing Complex Data Structures in Tcl</title>
  <link rel="stylesheet" href="manual.css">
</head>
<body>
<H2> 2 -  Representing Complex Data Structures in Tcl</H2>
<div class="blue">This chapter describes common approaches taken
to represent complex data structures in Tcl, their costs and
tradeoffs, and begins to describe some of Speed Tables' capabilities.</div>
<p>Tcl is not well-known for its ability to represent complex data
structures. Yes, it has <i>lists</i> and <i>associative arrays</i>
and, in Tcl 8.5, <i>dicts</i>. Yes, object-oriented extensions such
as <i>Incr Tcl</i> provide ways to plug objects together to represent
fairly complex data structures and yes, the <i>BLT toolkit</i>,
among others, has provided certain more efficient ways to represent
data (a vector data type, for instance) than available by default
and, yes, you can abuse <i>upvar</i> and <i>namespaces</i> as part
of expressing the structure of, and methods of access for, your
data.</p>
<p>There are, however, three typical problems with this approach:</p>
<ul>
<li><p>It is memory-inefficient.</p>
<p>Tables implemented using Tcl objects use an order of magnitude more memory than native C.</p>
<p>For example, an integer, stored as a Tcl object, has the integer
value and all the overhead of a Tcl object, 24 bytes minimum,
routinely more, and often way more. When constructing Tcl lists,
there is an overhead to making those lists, and the list structures
themselves consume memory, sometimes a surprising amount as Tcl
tries to avoid allocating memory on the fly by often allocating
more than you need, and sometimes much more than you need.
<a href=#1>[1]</a></p>
<p>Another drawback of Tcl arrays is that they store the field names (keys) along with each value, which is inherently necessary given their design but is yet another example of the inefficiency of this approach.</p>
<li><p>It is computationally inefficient.</p>
<p>Constructing, managing and manipulating complicated structures out of lists, arrays, etc, is quite processor-intensive when compared to, for instance, a hand-coded C-based approach exploiting pointers, C structs, and the like.</p>
<li><p>It yields code that is clumsy and obtuse.</p>
</ul>
<div class="blue-indent">Hackish construction of complex data structures sucks</div>
<p class="blue-block">Using a combination of <i>upvar</i> and <i>namespaces</i> and <i>lists</i> and <i>arrays</i> to represent a complex structure yields relatively opaque and inflexible ways of expressing and manipulating that structure, twisting the code and typically replicating little pieces of weird structure access drivel strewn throughout the application, making the code hard to follow, teach, fix, enhance, and hand off.</p>
<p><b>Speed tables</b> reads a structure definition and emits C code to create and manipulate tables of rows of that structure. We generate a full-fledged Tcl C extension that manages rows of fields as native C structs and emit subroutines for manipulating those rows in an efficient manner.</p>
<p>Memory efficiency is high because we have low per-row storage overhead beyond the size of the struct itself, and fields are stored in native formats such as short integer, integer, float, double, bit, etc.</p>
<p>Computational efficiency is high because we are reasonably clever about storing and fetching those values, particularly when populating from lines of tab-separated data as well as PostgreSQL database query results, inserting into them by reading rows from a Tcl channel containing tab-separated data, writing them tab-separated, locating them, updating them, and counting them, as well as importing and exporting by other means.</p>
<p>Speed tables avoids executing Tcl code on a per row basis when a lot of rows need to be looked at. In particular when bulk inserting and bulk processing via search, Tcl essentially configures an execution engine that can operate on millions of rows of data without the Tcl interpreter's per-row involvement except, perhaps, for example, executing scripted code only on the few rows that match your search criteria.</p>
<p>Speed tables also maintains a "null value" bit per field, unless told not to, and provide an out-of-band way to distinguish between null values and non-null values, as is present in SQL databases... providing a ready bridge between those databases and speed tables.</p>
<div class="blue-indent">Example Application</div>
<p class="blue-block">Speed tables is used as the realtime database for a monitoring system that polls millions of devices every few minutes. Device status and performance data is kept in speed tables. Information about the status of devices is continually "swept" to the SQL database at a sustainable rate. The loss of even a sizable number of scan results in the event of a crash is not a serious problem, as within a few minutes of starting up, the system will have obtained fresh data by newly polling the devices.</p>
<p>Speed tables supports defining skip list-based indexes on one or more fields in a row, providing multi-hundred-fold speed improvements for many searches. Fields that are not declared to be indexable do not have any code generated to check for the existence of indexes, etc, when they are changed, one of a number of optimizations performed to make speed tables fast.</p>
<a name=1><p class="foot">[1] It is common to see ten or twenty times the space consumed by the data itself used up by the Tcl objects, lists, arrays, etc, used to hold them. Even on a modern machine, using 20 gigabytes of memory to store a gigabyte of data is at a minimum kind of gross and, at worst, renders the solution unusable.)</p></a>
</body>
</html>
