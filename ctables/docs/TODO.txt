$Id$

Make it work with UTF8 chars.

Make sure the C source file and the
shared library is newer than the scarfed file and that the CVS version
of gentable that the stuff was built with hasn't altered.  This way if
the build previously failed for some reason or the version of gentable
got updated, that we still regenerate the shared library.

Have a way to find out if a field is null out-of-band, that is, some kind of
method called is_null or the like that will tell if you if a field or fields
is null.

It's easy to make the null_value setting be local to an instance of the
table and not global to all tables of a specific type.  tbl_ptr is defined
in the big case statement -- 

be able to import from an array, including only specific variables
NO - no easy way to get names of an array from C and anyway you can just
do a foo set $key field $array(field) field2 $array(field2), etc.

Add a way for someone doing a CTable definition to specify additional
files to include.

Add a way to write methods in C and add additional C code to the stuff
being generated, from the CTable definition.  This may also involve generating
a C include file that defines stuff that is otherwise defined in the
C source file we generate, so that you don't have to specify your C
code in some kind of quoted ctable definition.

Make set return a 1 if it created the row and a 0 if it already exists.
(Uh, not sure how valuable this actually is.)

Do something like GNU autoconf/configure or dig compiler switches, etc, out
of tclConfig.sh.

DONE Add an "incr" method.

DONE In search, make it store the native value being compared in a union in
the search component structure or something.  Compare that directly
rather than repetitively digging it out with Tcl_GetIntFromObj or
whatever, even though it's fast when it's native.
(Even better, we generate a row and put what we want in the field via a
standard *_set routine and possibly fiddle the null bit for the field.)

fixed strings allocate one more character than requested

provide a way for a ctable to provide a complete replayable definition
of itself.  Prefer to compile this into the C code so there's no way
it can get off from whatever files are in the vicinity.

implement btree-style index option for fields with both unique and not-unique
styles.

For big searches Tcl_NextHashEntry is responsible for almost 50% of the
overhead.  Unacceptable.  At the very least do a bidirectionally linked
list between rows in a table and traverse them that way.  (Hey, not bad.)
Or go to fancy skip lists or whatever and traverse them that way.  Skip
lists have easy and fast straight traversal.
Turns out skip lists are slower to traverse than the hash tables, however
we did implement the straight bidirectionally linked lists and it was a big
win.  DONE

Adopt TclX's test structure and make lots more tests.

In the _comp routine for varstring, if the pointer is NULL use the
default value for the field.

-----

DONE Generate a row when the search type is range and we're doing skip list
search.  Eventually make this generated row business, as used in the
skip list cmp routines, standard in other places.

----

read_tabsep can fail but add a thing where you can specify -error proc and
if it's going to fail and the error proc has been specified, it'll call
forward to the error proc rather than blowing out.

If it gets an error back from the error proc, it blows out.

If it gets a continue, it skips that row and continues.

If it just returns, like TCL_OK, in the result object will be a row that
read_tabsep should use in place place of the original, which is error
checked and called forward again should the returned thing have an error.

If it gets another error on the same column, then it'll error out.

---

Add a bytearray object.

---

Perhaps limit strings to 64K bytes to use shorts for the length and allocated
length.

Make skip lists support enforcement of unique constraint as they originally did.

Write the compiler debug flag into the stuff we see to see if anything got changed.

----

There's a fairly nasty bug involving both updating a row via set, inserting
a row via set, and inserting rows via read_tabsep when index inserts can
fail because of a unique constraint check.

The problem occurs when there are one or more unique indexes on a table.

Let's say an index insert fails due to the value not being unique.  Currently
we return an error but we do nothing to take the row out of the linked list
that every row is a part of and we do nothing to remove the row from any
indexes where insertion has already been successful.

This will lead to a protection violation of some sort as we do not know
that the thing isn't in one of its indexes and we will attempt to remove
it at deletion time or whatever.

If it's a new insert and there's an index insertion failure, the row should
not be inserted at all, i.e. be deinserted from any indexes it was successfully
inserted into, i.e. the insert fails.

If it's a modify, that's tougher.  SQL standard would say the row should
be left unmodified.  We could do it that way by knowing how much we'd
done and undoing it, which about for sure includes keeping a copy of the
row prior to making any changes.

Alternatively we can only not perform (or undo) the field changes that cause a
constraint violation.

I also want to do the callout thing for errors real soon.

---

Also I want to add some new options to search/search+ such as

    -delete 1 -- delete matching rows

    -into tableName -- copy matching fields from matching rows into table

---

Tcl's hash tables have a custom hash table capability where you supply 
pointers to a hash function, a key compare function, an allocator function 
and a free function so it's probably possible to have the hash keys be 
integers, doubles, inet, mac, etc, and even use the actual fields in the rows 
as the hash keys.

--

make delete_all_rows use the linked list [0] rather than walking the hash table.
make "names" method do the same.

make a speed table driver package that has all the non-generated source
like searching, sorting, hash tables, skip lists, etc, into a shared
library such that they aren't completely compiled every time.
